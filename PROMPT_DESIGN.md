## アプリケーションの名前
 AI秘書

## UI
 ブラウザ のチャット

## 技術スタック
 Python  
 LLM(Ollama)  
 MCP(MCP Python SDK)  
 SQLite  

## 概要
 文字入力に応答するアシスタント  
 MCP経由でユーザーの属性、ユーザーの記憶、ユーザーの目標、アシスタントへのお願い を読み込んで答えます  
 入力内容から、ユーザーの属性、ユーザーの目標、その他ユーザーの記憶、アシスタントへのお願い を自動で保存します（含まれない場合は記憶しない）  
 入力内容に記憶すべき内容が含まれているかどうかの判定もLLMを使用してください  
 保存処理はMCP経由でも、直接ＤＢへ書き込む方式でも、どちらでもＯＫ（実装と実行コストから決定）  
 MCP経由で取得する内容（コンテキスト）をなるべく少なくするため、API設計を工夫する  
 トークン圧縮のため、最後の入力から５分経過するか、"ありがとう"と入力されると、それ以前のメッセージは参照しないようにする（画面には残す）  
 ＤＢの保守画面を作成（参照、変更、削除）  
 テストモードを作成（Ollamaで渡すコンテキストを全て表示するモード）   
 （予定）記憶の圧縮機能を備えます。属性/目標のアップデート。記憶の修正や統合、そして圧縮を行います。長期記憶ほど短く圧縮していく（人間の記憶システムを参考）  

## フロー
 入力テキスト → システムプロンプト + 入力履歴 + テキスト -> Ollama -> MCPで検索 -> 応答 -> 
 （ユーザーが応答を読む時間に）入力テキストの内容をOllamaで解析 → （必要なら）ＤＢに記録  
 Ollamaへ並列してリクエストしない
 
## 実行環境
 3070tiを搭載したWindows11のノートパソコン

## その他要望
 このプロジェクトは私が使用する予定ではありますが、LLMを使ったシステム構築を学ぶたため企画したものです。Pythonも基本構文以上の知識はありません。HTMLやCSSの知識も怪しいです。なので、可能な限り私の学びになるように細かく日本語のコメントを入れて下さい。
